{
  "provider": "vercel",
  "model_count": 117,
  "models": [
    {
      "id": "vercel/xai/grok-code-fast-1",
      "name": "xai/grok-code-fast-1",
      "provider": "vercel",
      "model_id": "grok-code-fast-1",
      "input_price_per_million": 0.19999999999999998,
      "output_price_per_million": 1.5,
      "model_type": "code"
    },
    {
      "id": "vercel/anthropic/claude-sonnet-4.5",
      "name": "anthropic/claude-sonnet-4.5",
      "provider": "vercel",
      "model_id": "claude-sonnet-4.5",
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "gpqa_diamond": 0.737,
        "math_level_5": 0.977,
        "otis_mock_aime_2024_2025": 0.356,
        "frontiermath": 0.093,
        "frontiermath_tier_4": 0.021,
        "simpleqa_verified": 0.13,
        "swe_bench_verified": 0.648,
        "deep_research_bench": 0.577,
        "swe_bench": 0.648,
        "livebench_global": 56.6,
        "livebench_reasoning": 42.29,
        "livebench_coding": 76.07,
        "livebench_agentic_coding": 48.33,
        "livebench_math": 62.62,
        "livebench_data_analysis": 67.34,
        "livebench_language": 76.0,
        "livebench_ifeval": 23.52
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-2.5-flash-lite",
      "name": "google/gemini-2.5-flash-lite",
      "provider": "vercel",
      "model_id": "gemini-2.5-flash-lite",
      "input_price_per_million": "0.50",
      "output_price_per_million": "2.00",
      "model_type": "vision"
    },
    {
      "id": "vercel/google/gemini-3-flash",
      "name": "google/gemini-3-flash",
      "provider": "vercel",
      "model_id": "gemini-3-flash",
      "input_price_per_million": "0.50",
      "output_price_per_million": "3.00",
      "benchmarks": {
        "gpqa_diamond": 0.832,
        "otis_mock_aime_2024_2025": 0.928,
        "frontiermath": 0.356,
        "simplebench": 0.611,
        "frontiermath_tier_4": 0.042,
        "simpleqa_verified": 0.674,
        "chess_puzzles": 0.38,
        "arena_elo": 1471.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-5.2",
      "name": "openai/gpt-5.2",
      "provider": "vercel",
      "model_id": "gpt-5.2",
      "input_price_per_million": 0.875,
      "output_price_per_million": 7.0,
      "benchmarks": {
        "arena_elo": 1425.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-haiku-4.5",
      "name": "anthropic/claude-haiku-4.5",
      "provider": "vercel",
      "model_id": "claude-haiku-4.5",
      "input_price_per_million": 1.0,
      "output_price_per_million": 5.0,
      "benchmarks": {
        "gpqa_diamond": 0.605,
        "math_level_5": 0.869,
        "otis_mock_aime_2024_2025": 0.358,
        "frontiermath": 0.041,
        "swe_bench_verified": 0.606,
        "swe_bench": 0.606,
        "livebench_global": 48.34,
        "livebench_reasoning": 33.94,
        "livebench_coding": 72.17,
        "livebench_agentic_coding": 33.33,
        "livebench_math": 57.97,
        "livebench_data_analysis": 66.19,
        "livebench_language": 57.05,
        "livebench_ifeval": 17.75
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-opus-4.5",
      "name": "anthropic/claude-opus-4.5",
      "provider": "vercel",
      "model_id": "claude-opus-4.5",
      "input_price_per_million": 5.0,
      "output_price_per_million": 25.0,
      "benchmarks": {
        "gpqa_diamond": 0.807,
        "otis_mock_aime_2024_2025": 0.481,
        "frontiermath": 0.207,
        "simplebench": 0.62,
        "frontiermath_tier_4": 0.042
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-3-pro-preview",
      "name": "google/gemini-3-pro-preview",
      "provider": "vercel",
      "model_id": "gemini-3-pro-preview",
      "input_price_per_million": "2.00",
      "output_price_per_million": "12.00",
      "benchmarks": {
        "gpqa_diamond": 0.926,
        "otis_mock_aime_2024_2025": 0.914,
        "frontiermath": 0.376,
        "simplebench": 0.764,
        "frontiermath_tier_4": 0.188,
        "simpleqa_verified": 0.729,
        "chess_puzzles": 0.31,
        "humanitys_last_exam": 0.375,
        "frontier_math": 0.376,
        "arena_elo": 1490.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/anthropic/claude-3.7-sonnet",
      "name": "anthropic/claude-3.7-sonnet",
      "provider": "vercel",
      "model_id": "claude-3.7-sonnet",
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "gpqa_diamond": 0.66,
        "math_level_5": 0.682,
        "otis_mock_aime_2024_2025": 0.219,
        "frontiermath": 0.031,
        "aider_polyglot": 60.4,
        "simplebench": 0.449,
        "swe_bench_verified": 0.522
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/anthropic/claude-sonnet-4",
      "name": "anthropic/claude-sonnet-4",
      "provider": "vercel",
      "model_id": "claude-sonnet-4",
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "gpqa_diamond": 0.667,
        "math_level_5": 0.844,
        "otis_mock_aime_2024_2025": 0.289,
        "frontiermath": 0.041,
        "aider_polyglot": 56.4,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.606,
        "terminal_bench": 0.548,
        "swe_bench": 0.606,
        "livebench_global": 53.93,
        "livebench_reasoning": 39.67,
        "livebench_coding": 80.74,
        "livebench_agentic_coding": 38.33,
        "livebench_math": 60.36,
        "livebench_data_analysis": 64.68,
        "livebench_language": 71.01,
        "livebench_ifeval": 22.68
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-4.1-mini",
      "name": "openai/gpt-4.1-mini",
      "provider": "vercel",
      "model_id": "gpt-4.1-mini",
      "input_price_per_million": 0.2,
      "output_price_per_million": 0.8,
      "benchmarks": {
        "gpqa_diamond": 0.658,
        "mmlu": 87.5,
        "math_level_5": 0.873,
        "otis_mock_aime_2024_2025": 0.447,
        "frontiermath": 0.045,
        "aider_polyglot": 32.4,
        "swe_bench_verified": 0.328,
        "humaneval": 93.8,
        "arena_elo": 1381.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/xai/grok-4.1-fast-non-reasoning",
      "name": "xai/grok-4.1-fast-non-reasoning",
      "provider": "vercel",
      "model_id": "grok-4.1-fast-non-reasoning",
      "benchmarks": {
        "simplebench": 0.56,
        "livebench_global": 35.97,
        "livebench_reasoning": 23.35,
        "livebench_coding": 54.26,
        "livebench_agentic_coding": 10.0,
        "livebench_math": 38.92,
        "livebench_data_analysis": 58.26,
        "livebench_language": 50.01,
        "livebench_ifeval": 16.98
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-2.5-flash",
      "name": "google/gemini-2.5-flash",
      "provider": "vercel",
      "model_id": "gemini-2.5-flash",
      "input_price_per_million": "0.30",
      "output_price_per_million": "2.50",
      "benchmarks": {
        "frontiermath": 0.048,
        "simplebench": 0.412,
        "frontiermath_tier_4": 0.042,
        "arena_elo": 1408.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-5-chat",
      "name": "openai/gpt-5-chat",
      "provider": "vercel",
      "model_id": "gpt-5-chat",
      "input_price_per_million": 0.625,
      "output_price_per_million": 5.0,
      "benchmarks": {
        "arena_elo": 1425.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/deepseek/deepseek-v3.2",
      "name": "deepseek/deepseek-v3.2",
      "provider": "vercel",
      "model_id": "deepseek-v3.2",
      "input_price_per_million": 0.25,
      "output_price_per_million": 0.38,
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/gpt-5-nano",
      "name": "openai/gpt-5-nano",
      "provider": "vercel",
      "model_id": "gpt-5-nano",
      "input_price_per_million": 0.025,
      "output_price_per_million": 0.2,
      "benchmarks": {
        "livebench_global": 51.61,
        "livebench_reasoning": 35.45,
        "livebench_coding": 67.38,
        "livebench_agentic_coding": 28.33,
        "livebench_math": 64.7,
        "livebench_data_analysis": 65.73,
        "livebench_language": 47.73,
        "livebench_ifeval": 51.98
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-2.5-flash-lite-preview-09-2025",
      "name": "google/gemini-2.5-flash-lite-preview-09-2025",
      "provider": "vercel",
      "model_id": "gemini-2.5-flash-lite-preview-09-2025",
      "input_price_per_million": 0.09999999999999999,
      "output_price_per_million": 0.39999999999999997,
      "model_type": "vision"
    },
    {
      "id": "vercel/google/gemini-2.0-flash",
      "name": "google/gemini-2.0-flash",
      "provider": "vercel",
      "model_id": "gemini-2.0-flash",
      "input_price_per_million": "0.10",
      "output_price_per_million": "0.40",
      "benchmarks": {
        "mmlu": 0.797,
        "aider_polyglot": 22.2,
        "simplebench": 0.189
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-5",
      "name": "openai/gpt-5",
      "provider": "vercel",
      "model_id": "gpt-5",
      "input_price_per_million": 0.625,
      "output_price_per_million": 5.0,
      "benchmarks": {
        "arena_elo": 1425.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-2.5-pro",
      "name": "google/gemini-2.5-pro",
      "provider": "vercel",
      "model_id": "gemini-2.5-pro",
      "input_price_per_million": "1.25",
      "output_price_per_million": "10.00",
      "benchmarks": {
        "gpqa_diamond": 0.853,
        "otis_mock_aime_2024_2025": 0.842,
        "frontiermath": 0.141,
        "frontiermath_tier_4": 0.042,
        "simpleqa_verified": 0.56,
        "chess_puzzles": 0.2,
        "arena_elo": 1450.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/mistral/devstral-2",
      "name": "mistral/devstral-2",
      "provider": "vercel",
      "model_id": "devstral-2",
      "benchmarks": {
        "livebench_global": 43.79,
        "livebench_reasoning": 27.74,
        "livebench_coding": 66.79,
        "livebench_agentic_coding": 43.33,
        "livebench_math": 52.52,
        "livebench_data_analysis": 56.95,
        "livebench_language": 45.67,
        "livebench_ifeval": 13.5
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/gpt-5.1-thinking",
      "name": "openai/gpt-5.1-thinking",
      "provider": "vercel",
      "model_id": "gpt-5.1-thinking",
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-5-mini",
      "name": "openai/gpt-5-mini",
      "provider": "vercel",
      "model_id": "gpt-5-mini",
      "input_price_per_million": 0.125,
      "output_price_per_million": 1.0,
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-oss-120b",
      "name": "openai/gpt-oss-120b",
      "provider": "vercel",
      "model_id": "gpt-oss-120b",
      "input_price_per_million": 0.039,
      "output_price_per_million": 0.19,
      "benchmarks": {
        "simplebench": 0.221,
        "arena_elo": 1353.0,
        "livebench_global": 48.66,
        "livebench_reasoning": 39.21,
        "livebench_coding": 60.21,
        "livebench_agentic_coding": 16.67,
        "livebench_math": 68.87,
        "livebench_data_analysis": 56.77,
        "livebench_language": 48.59,
        "livebench_ifeval": 50.29
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/xai/grok-4-fast-non-reasoning",
      "name": "xai/grok-4-fast-non-reasoning",
      "provider": "vercel",
      "model_id": "grok-4-fast-non-reasoning",
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-5.1-instant",
      "name": "openai/gpt-5.1-instant",
      "provider": "vercel",
      "model_id": "gpt-5.1-instant",
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-5-codex",
      "name": "openai/gpt-5-codex",
      "provider": "vercel",
      "model_id": "gpt-5-codex",
      "input_price_per_million": 1.25,
      "output_price_per_million": 10.0,
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-oss-safeguard-20b",
      "name": "openai/gpt-oss-safeguard-20b",
      "provider": "vercel",
      "model_id": "gpt-oss-safeguard-20b",
      "input_price_per_million": 0.075,
      "output_price_per_million": 0.3,
      "model_type": "chat"
    },
    {
      "id": "vercel/mistral/devstral-small-2",
      "name": "mistral/devstral-small-2",
      "provider": "vercel",
      "model_id": "devstral-small-2",
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/text-embedding-3-small",
      "name": "openai/text-embedding-3-small",
      "provider": "vercel",
      "model_id": "text-embedding-3-small",
      "input_price_per_million": 0.02,
      "model_type": "embedding"
    },
    {
      "id": "vercel/xai/grok-4.1-fast-reasoning",
      "name": "xai/grok-4.1-fast-reasoning",
      "provider": "vercel",
      "model_id": "grok-4.1-fast-reasoning",
      "benchmarks": {
        "arena_elo": 1431.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-4o-mini",
      "name": "openai/gpt-4o-mini",
      "provider": "vercel",
      "model_id": "gpt-4o-mini",
      "input_price_per_million": 0.075,
      "output_price_per_million": 0.3,
      "benchmarks": {
        "gpqa_diamond": 0.377,
        "mmlu": 82.0,
        "math_level_5": 0.526,
        "gsm8k": 0.913,
        "otis_mock_aime_2024_2025": 0.069,
        "aider_polyglot": 3.6,
        "simplebench": 0.107,
        "humaneval": 87.2,
        "arena_elo": 1317.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/mistral/mistral-embed",
      "name": "mistral/mistral-embed",
      "provider": "vercel",
      "model_id": "mistral-embed",
      "input_price_per_million": 0.1,
      "model_type": "embedding"
    },
    {
      "id": "vercel/mistral/ministral-3b",
      "name": "mistral/ministral-3b",
      "provider": "vercel",
      "model_id": "ministral-3b",
      "input_price_per_million": 0.1,
      "output_price_per_million": 0.1,
      "benchmarks": {
        "gpqa_diamond": 0.253,
        "math_level_5": 0.144
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/gpt-4o",
      "name": "openai/gpt-4o",
      "provider": "vercel",
      "model_id": "gpt-4o",
      "input_price_per_million": 1.25,
      "output_price_per_million": 5.0,
      "benchmarks": {
        "gpqa_diamond": 0.489,
        "mmlu": 87.2,
        "math_level_5": 0.533,
        "otis_mock_aime_2024_2025": 0.062,
        "frontiermath": 0.003,
        "aider_polyglot": 18.2,
        "simplebench": 0.178,
        "swe_bench_verified": 0.254,
        "humaneval": 91.0,
        "arena_elo": 1335.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-4.1",
      "name": "openai/gpt-4.1",
      "provider": "vercel",
      "model_id": "gpt-4.1",
      "input_price_per_million": 1.0,
      "output_price_per_million": 4.0,
      "benchmarks": {
        "gpqa_diamond": 0.669,
        "mmlu": 90.2,
        "math_level_5": 0.83,
        "otis_mock_aime_2024_2025": 0.383,
        "frontiermath": 0.055,
        "aider_polyglot": 52.4,
        "simplebench": 0.27,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.41,
        "humaneval": 94.5,
        "arena_elo": 1412.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-4.1-nano",
      "name": "openai/gpt-4.1-nano",
      "provider": "vercel",
      "model_id": "gpt-4.1-nano",
      "input_price_per_million": 0.05,
      "output_price_per_million": 0.2,
      "benchmarks": {
        "gpqa_diamond": 0.489,
        "mmlu": 80.1,
        "math_level_5": 0.7,
        "otis_mock_aime_2024_2025": 0.289,
        "frontiermath": 0.01,
        "aider_polyglot": 8.9,
        "humaneval": 87.0,
        "arena_elo": 1321.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/xai/grok-4",
      "name": "xai/grok-4",
      "provider": "vercel",
      "model_id": "grok-4",
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "gpqa_diamond": 0.87,
        "otis_mock_aime_2024_2025": 0.84,
        "frontiermath": 0.197,
        "aider_polyglot": 79.6,
        "simplebench": 0.605,
        "frontiermath_tier_4": 0.021,
        "simpleqa_verified": 0.479,
        "chess_puzzles": 0.351,
        "arena_elo": 1409.0,
        "livebench_global": 62.9,
        "livebench_reasoning": 79.13,
        "livebench_coding": 73.13,
        "livebench_agentic_coding": 30.0,
        "livebench_math": 83.02,
        "livebench_data_analysis": 69.53,
        "livebench_language": 76.39,
        "livebench_ifeval": 29.07
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-2.5-flash-image",
      "name": "google/gemini-2.5-flash-image",
      "provider": "vercel",
      "model_id": "gemini-2.5-flash-image",
      "input_price_per_million": "0.30",
      "output_price_per_million": "0.039",
      "model_type": "vision"
    },
    {
      "id": "vercel/xai/grok-4-fast-reasoning",
      "name": "xai/grok-4-fast-reasoning",
      "provider": "vercel",
      "model_id": "grok-4-fast-reasoning",
      "benchmarks": {
        "arena_elo": 1402.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/deepseek/deepseek-v3.2-thinking",
      "name": "deepseek/deepseek-v3.2-thinking",
      "provider": "vercel",
      "model_id": "deepseek-v3.2-thinking",
      "benchmarks": {
        "aider_polyglot": 74.2,
        "arena_elo": 1419.0,
        "livebench_global": 61.94,
        "livebench_reasoning": 64.37,
        "livebench_coding": 70.06,
        "livebench_agentic_coding": 31.67,
        "livebench_math": 82.4,
        "livebench_data_analysis": 72.78,
        "livebench_language": 71.06,
        "livebench_ifeval": 41.27
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/anthropic/claude-opus-4.1",
      "name": "anthropic/claude-opus-4.1",
      "provider": "vercel",
      "model_id": "claude-opus-4.1",
      "input_price_per_million": 15.0,
      "output_price_per_million": 75.0,
      "benchmarks": {
        "gpqa_diamond": 0.732,
        "otis_mock_aime_2024_2025": 0.4,
        "frontiermath": 0.059,
        "simplebench": 0.6,
        "swe_bench_verified": 0.632,
        "deep_research_bench": 0.564,
        "terminal_bench": 0.588,
        "swe_bench": 0.632,
        "livebench_global": 57.54,
        "livebench_reasoning": 40.89,
        "livebench_coding": 76.07,
        "livebench_agentic_coding": 53.33,
        "livebench_math": 62.83,
        "livebench_data_analysis": 66.95,
        "livebench_language": 76.75,
        "livebench_ifeval": 25.92
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-3-pro-image",
      "name": "google/gemini-3-pro-image",
      "provider": "vercel",
      "model_id": "gemini-3-pro-image",
      "input_price_per_million": "2.00",
      "output_price_per_million": "12.00",
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-5.1-codex-max",
      "name": "openai/gpt-5.1-codex-max",
      "provider": "vercel",
      "model_id": "gpt-5.1-codex-max",
      "input_price_per_million": 1.25,
      "output_price_per_million": 10.0,
      "model_type": "chat"
    },
    {
      "id": "vercel/google/gemini-embedding-001",
      "name": "google/gemini-embedding-001",
      "provider": "vercel",
      "model_id": "gemini-embedding-001",
      "input_price_per_million": "0.15",
      "output_price_per_million": "2.50",
      "model_type": "embedding"
    },
    {
      "id": "vercel/perplexity/sonar",
      "name": "perplexity/sonar",
      "provider": "vercel",
      "model_id": "sonar",
      "input_price_per_million": 1.0,
      "output_price_per_million": 1.0,
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/text-embedding-3-large",
      "name": "openai/text-embedding-3-large",
      "provider": "vercel",
      "model_id": "text-embedding-3-large",
      "input_price_per_million": 0.13,
      "model_type": "embedding"
    },
    {
      "id": "vercel/openai/gpt-5.1-codex-mini",
      "name": "openai/gpt-5.1-codex-mini",
      "provider": "vercel",
      "model_id": "gpt-5.1-codex-mini",
      "input_price_per_million": 0.25,
      "output_price_per_million": 2.0,
      "benchmarks": {
        "livebench_global": 63.32,
        "livebench_reasoning": 64.71,
        "livebench_coding": 69.93,
        "livebench_agentic_coding": 40.0,
        "livebench_math": 76.26,
        "livebench_data_analysis": 70.29,
        "livebench_language": 63.01,
        "livebench_ifeval": 59.02
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/deepseek/deepseek-v3.2-exp",
      "name": "deepseek/deepseek-v3.2-exp",
      "provider": "vercel",
      "model_id": "deepseek-v3.2-exp",
      "input_price_per_million": 0.25,
      "output_price_per_million": 0.38,
      "benchmarks": {
        "aider_polyglot": 70.2,
        "arena_elo": 1423.0,
        "livebench_global": 52.82,
        "livebench_reasoning": 45.5,
        "livebench_coding": 73.19,
        "livebench_agentic_coding": 36.67,
        "livebench_math": 64.38,
        "livebench_data_analysis": 65.09,
        "livebench_language": 65.6,
        "livebench_ifeval": 19.33
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/mistral/mistral-small",
      "name": "mistral/mistral-small",
      "provider": "vercel",
      "model_id": "mistral-small",
      "input_price_per_million": 0.1,
      "output_price_per_million": 0.3,
      "benchmarks": {
        "gpqa_diamond": 0.453,
        "mmlu": 0.687,
        "math_level_5": 0.448,
        "otis_mock_aime_2024_2025": 0.058,
        "arena_elo": 1355.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/deepseek/deepseek-r1",
      "name": "deepseek/deepseek-r1",
      "provider": "vercel",
      "model_id": "deepseek-r1",
      "input_price_per_million": 0.39999999999999997,
      "output_price_per_million": 1.75,
      "benchmarks": {
        "gpqa_diamond": 0.692,
        "math_level_5": 0.931,
        "otis_mock_aime_2024_2025": 0.533,
        "aider_polyglot": 56.9,
        "simplebench": 0.309,
        "simpleqa_verified": 0.274,
        "swe_bench_verified": 0.333,
        "arena_elo": 1396.0
      },
      "model_type": "reasoning"
    },
    {
      "id": "vercel/deepseek/deepseek-v3.1",
      "name": "deepseek/deepseek-v3.1",
      "provider": "vercel",
      "model_id": "deepseek-v3.1",
      "input_price_per_million": 0.15,
      "output_price_per_million": 0.75,
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/google/gemini-2.5-flash-image-preview",
      "name": "google/gemini-2.5-flash-image-preview",
      "provider": "vercel",
      "model_id": "gemini-2.5-flash-image-preview",
      "input_price_per_million": "0.30",
      "output_price_per_million": "0.039",
      "model_type": "vision"
    },
    {
      "id": "vercel/deepseek/deepseek-v3",
      "name": "deepseek/deepseek-v3",
      "provider": "vercel",
      "model_id": "deepseek-v3",
      "input_price_per_million": 0.19,
      "output_price_per_million": 0.87,
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/gpt-5.2-chat",
      "name": "openai/gpt-5.2-chat",
      "provider": "vercel",
      "model_id": "gpt-5.2-chat",
      "input_price_per_million": 0.875,
      "output_price_per_million": 7.0,
      "benchmarks": {
        "arena_elo": 1425.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/perplexity/sonar-reasoning-pro",
      "name": "perplexity/sonar-reasoning-pro",
      "provider": "vercel",
      "model_id": "sonar-reasoning-pro",
      "input_price_per_million": 2.0,
      "output_price_per_million": 8.0,
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/o4-mini",
      "name": "openai/o4-mini",
      "provider": "vercel",
      "model_id": "o4-mini",
      "input_price_per_million": 0.55,
      "output_price_per_million": 2.2,
      "benchmarks": {
        "mmlu": 90.0,
        "humaneval": 97.3,
        "arena_elo": 1391.0
      },
      "model_type": "reasoning"
    },
    {
      "id": "vercel/google/gemini-2.0-flash-lite",
      "name": "google/gemini-2.0-flash-lite",
      "provider": "vercel",
      "model_id": "gemini-2.0-flash-lite",
      "input_price_per_million": "0.075",
      "output_price_per_million": "0.30",
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-oss-20b",
      "name": "openai/gpt-oss-20b",
      "provider": "vercel",
      "model_id": "gpt-oss-20b",
      "input_price_per_million": 0.02,
      "output_price_per_million": 0.09999999999999999,
      "benchmarks": {
        "arena_elo": 1318.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-3.5-sonnet",
      "name": "anthropic/claude-3.5-sonnet",
      "provider": "vercel",
      "model_id": "claude-3.5-sonnet",
      "input_price_per_million": 6.0,
      "output_price_per_million": 30.0,
      "benchmarks": {
        "gpqa_diamond": 0.54,
        "mmlu": 0.873,
        "math_level_5": 0.517,
        "otis_mock_aime_2024_2025": 0.085,
        "frontiermath": 0.021,
        "aider_polyglot": 51.6,
        "simplebench": 0.275,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.406
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/gpt-5.1-codex",
      "name": "openai/gpt-5.1-codex",
      "provider": "vercel",
      "model_id": "gpt-5.1-codex",
      "input_price_per_million": 1.25,
      "output_price_per_million": 10.0,
      "benchmarks": {
        "livebench_global": 69.76,
        "livebench_reasoning": 81.98,
        "livebench_coding": 71.78,
        "livebench_agentic_coding": 53.33,
        "livebench_math": 79.58,
        "livebench_data_analysis": 68.8,
        "livebench_language": 69.48,
        "livebench_ifeval": 63.39
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-3.5-haiku",
      "name": "anthropic/claude-3.5-haiku",
      "provider": "vercel",
      "model_id": "claude-3.5-haiku",
      "input_price_per_million": 0.7999999999999999,
      "output_price_per_million": 4.0,
      "benchmarks": {
        "gpqa_diamond": 0.381,
        "mmlu": 0.743,
        "math_level_5": 0.464,
        "otis_mock_aime_2024_2025": 0.043,
        "frontiermath": 0.003,
        "aider_polyglot": 28.0,
        "simpleqa_verified": 0.067
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/o3-mini",
      "name": "openai/o3-mini",
      "provider": "vercel",
      "model_id": "o3-mini",
      "input_price_per_million": 0.55,
      "output_price_per_million": 2.2,
      "benchmarks": {
        "mmlu": 85.9,
        "humaneval": 96.3,
        "arena_elo": 1348.0
      },
      "model_type": "reasoning"
    },
    {
      "id": "vercel/google/gemini-2.5-flash-preview-09-2025",
      "name": "google/gemini-2.5-flash-preview-09-2025",
      "provider": "vercel",
      "model_id": "gemini-2.5-flash-preview-09-2025",
      "input_price_per_million": "0.30",
      "output_price_per_million": "2.50",
      "benchmarks": {
        "arena_elo": 1405.0
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/meta/llama-3.3-70b",
      "name": "meta/llama-3.3-70b",
      "provider": "vercel",
      "model_id": "llama-3.3-70b",
      "input_price_per_million": 0.09999999999999999,
      "output_price_per_million": 0.32,
      "benchmarks": {
        "gpqa_diamond": 0.474,
        "mmlu": 0.863,
        "math_level_5": 0.416,
        "otis_mock_aime_2024_2025": 0.051,
        "simplebench": 0.199
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/cohere/embed-v4.0",
      "name": "cohere/embed-v4.0",
      "provider": "vercel",
      "model_id": "embed-v4.0",
      "model_type": "embedding"
    },
    {
      "id": "vercel/openai/o3",
      "name": "openai/o3",
      "provider": "vercel",
      "model_id": "o3",
      "input_price_per_million": 1.0,
      "output_price_per_million": 4.0,
      "benchmarks": {
        "mmlu": 92.9,
        "humaneval": 87.4,
        "arena_elo": 1433.0
      },
      "model_type": "reasoning"
    },
    {
      "id": "vercel/meta/llama-3.1-8b",
      "name": "meta/llama-3.1-8b",
      "provider": "vercel",
      "model_id": "llama-3.1-8b",
      "input_price_per_million": 0.152,
      "output_price_per_million": 0.287,
      "benchmarks": {
        "gpqa_diamond": 0.259,
        "mmlu": 0.561,
        "math_level_5": 0.229,
        "gsm8k": 0.824,
        "otis_mock_aime_2024_2025": 0.025
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/deepseek/deepseek-v3.1-terminus",
      "name": "deepseek/deepseek-v3.1-terminus",
      "provider": "vercel",
      "model_id": "deepseek-v3.1-terminus",
      "input_price_per_million": 0.21,
      "output_price_per_million": 0.7899999999999999,
      "benchmarks": {
        "arena_elo": 1415.0
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/mistral/mistral-large-3",
      "name": "mistral/mistral-large-3",
      "provider": "vercel",
      "model_id": "mistral-large-3",
      "benchmarks": {
        "arena_elo": 1413.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-5.2-pro",
      "name": "openai/gpt-5.2-pro",
      "provider": "vercel",
      "model_id": "gpt-5.2-pro",
      "input_price_per_million": 10.5,
      "output_price_per_million": 84.0,
      "model_type": "chat"
    },
    {
      "id": "vercel/google/text-embedding-005",
      "name": "google/text-embedding-005",
      "provider": "vercel",
      "model_id": "text-embedding-005",
      "model_type": "embedding"
    },
    {
      "id": "vercel/perplexity/sonar-pro",
      "name": "perplexity/sonar-pro",
      "provider": "vercel",
      "model_id": "sonar-pro",
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "model_type": "unknown"
    },
    {
      "id": "vercel/xai/grok-3-mini",
      "name": "xai/grok-3-mini",
      "provider": "vercel",
      "model_id": "grok-3-mini",
      "input_price_per_million": 0.3,
      "output_price_per_million": 0.5,
      "model_type": "chat"
    },
    {
      "id": "vercel/mistral/ministral-14b",
      "name": "mistral/ministral-14b",
      "provider": "vercel",
      "model_id": "ministral-14b",
      "input_price_per_million": 0.2,
      "output_price_per_million": 0.2,
      "model_type": "unknown"
    },
    {
      "id": "vercel/xai/grok-2-vision",
      "name": "xai/grok-2-vision",
      "provider": "vercel",
      "model_id": "grok-2-vision",
      "model_type": "vision"
    },
    {
      "id": "vercel/xai/grok-3",
      "name": "xai/grok-3",
      "provider": "vercel",
      "model_id": "grok-3",
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "simplebench": 0.361
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/meta/llama-4-scout",
      "name": "meta/llama-4-scout",
      "provider": "vercel",
      "model_id": "llama-4-scout",
      "input_price_per_million": 0.08,
      "output_price_per_million": 0.3,
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-opus-4",
      "name": "anthropic/claude-opus-4",
      "provider": "vercel",
      "model_id": "claude-opus-4",
      "input_price_per_million": 15.0,
      "output_price_per_million": 75.0,
      "benchmarks": {
        "gpqa_diamond": 0.692,
        "math_level_5": 0.85,
        "otis_mock_aime_2024_2025": 0.422,
        "frontiermath": 0.045,
        "aider_polyglot": 70.7,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.622,
        "deep_research_bench": 0.563,
        "terminal_bench": 0.453,
        "swe_bench": 0.622
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/mistral/pixtral-12b",
      "name": "mistral/pixtral-12b",
      "provider": "vercel",
      "model_id": "pixtral-12b",
      "input_price_per_million": 0.15,
      "output_price_per_million": 0.15,
      "model_type": "vision"
    },
    {
      "id": "vercel/mistral/ministral-8b",
      "name": "mistral/ministral-8b",
      "provider": "vercel",
      "model_id": "ministral-8b",
      "input_price_per_million": 0.15,
      "output_price_per_million": 0.15,
      "benchmarks": {
        "gpqa_diamond": 0.271,
        "math_level_5": 0.149,
        "arena_elo": 1237.0
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/text-embedding-ada-002",
      "name": "openai/text-embedding-ada-002",
      "provider": "vercel",
      "model_id": "text-embedding-ada-002",
      "input_price_per_million": 0.1,
      "model_type": "embedding"
    },
    {
      "id": "vercel/meta/llama-4-maverick",
      "name": "meta/llama-4-maverick",
      "provider": "vercel",
      "model_id": "llama-4-maverick",
      "input_price_per_million": 0.15,
      "output_price_per_million": 0.6,
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-3-haiku",
      "name": "anthropic/claude-3-haiku",
      "provider": "vercel",
      "model_id": "claude-3-haiku",
      "input_price_per_million": 0.25,
      "output_price_per_million": 1.25,
      "benchmarks": {
        "gpqa_diamond": 0.363,
        "mmlu": 0.738,
        "math_level_5": 0.149,
        "otis_mock_aime_2024_2025": 0.018
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/openai/o1",
      "name": "openai/o1",
      "provider": "vercel",
      "model_id": "o1",
      "input_price_per_million": 7.5,
      "output_price_per_million": 30.0,
      "benchmarks": {
        "gpqa_diamond": 0.503,
        "mmlu": 90.8,
        "math_level_5": 0.816,
        "otis_mock_aime_2024_2025": 0.311,
        "simplebench": 0.417,
        "humaneval": 92.4,
        "arena_elo": 1388.0
      },
      "model_type": "reasoning"
    },
    {
      "id": "vercel/mistral/mistral-medium",
      "name": "mistral/mistral-medium",
      "provider": "vercel",
      "model_id": "mistral-medium",
      "input_price_per_million": 0.4,
      "output_price_per_million": 2.0,
      "benchmarks": {
        "gpqa_diamond": 0.595,
        "math_level_5": 0.816,
        "otis_mock_aime_2024_2025": 0.322,
        "frontiermath": 0.003,
        "arena_elo": 1223.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-4-turbo",
      "name": "openai/gpt-4-turbo",
      "provider": "vercel",
      "model_id": "gpt-4-turbo",
      "input_price_per_million": 10.0,
      "output_price_per_million": 30.0,
      "benchmarks": {
        "gpqa_diamond": 0.466,
        "mmlu": 86.7,
        "math_level_5": 0.467,
        "otis_mock_aime_2024_2025": 0.067,
        "simplebench": 0.251,
        "humaneval": 88.2,
        "arena_elo": 1324.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/xai/grok-3-fast",
      "name": "xai/grok-3-fast",
      "provider": "vercel",
      "model_id": "grok-3-fast",
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/gpt-3.5-turbo",
      "name": "openai/gpt-3.5-turbo",
      "provider": "vercel",
      "model_id": "gpt-3.5-turbo",
      "input_price_per_million": 0.5,
      "output_price_per_million": 1.5,
      "benchmarks": {
        "gpqa_diamond": 0.272,
        "mmlu": 0.714,
        "math_level_5": 0.159,
        "gsm8k": 0.578,
        "trivia_qa": 0.858,
        "arena_elo": 1202.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/text-multilingual-embedding-002",
      "name": "google/text-multilingual-embedding-002",
      "provider": "vercel",
      "model_id": "text-multilingual-embedding-002",
      "model_type": "embedding"
    },
    {
      "id": "vercel/mistral/codestral",
      "name": "mistral/codestral",
      "provider": "vercel",
      "model_id": "codestral",
      "input_price_per_million": 0.3,
      "output_price_per_million": 0.9,
      "benchmarks": {
        "aider_polyglot": 11.1
      },
      "model_type": "code"
    },
    {
      "id": "vercel/openai/gpt-5-pro",
      "name": "openai/gpt-5-pro",
      "provider": "vercel",
      "model_id": "gpt-5-pro",
      "input_price_per_million": 7.5,
      "output_price_per_million": 60.0,
      "benchmarks": {
        "simplebench": 0.616,
        "livebench_global": 72.67,
        "livebench_reasoning": 81.69,
        "livebench_coding": 72.11,
        "livebench_agentic_coding": 51.67,
        "livebench_math": 86.17,
        "livebench_data_analysis": 72.42,
        "livebench_language": 80.69,
        "livebench_ifeval": 63.96
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/mistral/magistral-medium",
      "name": "mistral/magistral-medium",
      "provider": "vercel",
      "model_id": "magistral-medium",
      "input_price_per_million": 2.0,
      "output_price_per_million": 5.0,
      "benchmarks": {
        "arena_elo": 1305.0
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/meta/llama-3.2-3b",
      "name": "meta/llama-3.2-3b",
      "provider": "vercel",
      "model_id": "llama-3.2-3b",
      "input_price_per_million": 0.055,
      "output_price_per_million": 0.201,
      "model_type": "chat"
    },
    {
      "id": "vercel/xai/grok-3-mini-fast",
      "name": "xai/grok-3-mini-fast",
      "provider": "vercel",
      "model_id": "grok-3-mini-fast",
      "model_type": "chat"
    },
    {
      "id": "vercel/anthropic/claude-3.5-sonnet-20240620",
      "name": "anthropic/claude-3.5-sonnet-20240620",
      "provider": "vercel",
      "model_id": "claude-3.5-sonnet-20240620",
      "input_price_per_million": 6.0,
      "output_price_per_million": 30.0,
      "benchmarks": {
        "gpqa_diamond": 0.54,
        "mmlu": 0.873,
        "math_level_5": 0.517,
        "otis_mock_aime_2024_2025": 0.085,
        "frontiermath": 0.021,
        "aider_polyglot": 51.6,
        "simplebench": 0.275,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.406
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/anthropic/claude-3-opus",
      "name": "anthropic/claude-3-opus",
      "provider": "vercel",
      "model_id": "claude-3-opus",
      "benchmarks": {
        "gpqa_diamond": 0.472,
        "mmlu": 0.846,
        "math_level_5": 0.375,
        "otis_mock_aime_2024_2025": 0.047,
        "simplebench": 0.235
      },
      "model_type": "vision"
    },
    {
      "id": "vercel/mistral/pixtral-large",
      "name": "mistral/pixtral-large",
      "provider": "vercel",
      "model_id": "pixtral-large",
      "input_price_per_million": 2.0,
      "output_price_per_million": 6.0,
      "model_type": "vision"
    },
    {
      "id": "vercel/meta/llama-3.1-70b",
      "name": "meta/llama-3.1-70b",
      "provider": "vercel",
      "model_id": "llama-3.1-70b",
      "input_price_per_million": 0.293,
      "output_price_per_million": 2.253,
      "benchmarks": {
        "gpqa_diamond": 0.442,
        "mmlu": 0.801,
        "math_level_5": 0.367,
        "otis_mock_aime_2024_2025": 0.036
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/o3-pro",
      "name": "openai/o3-pro",
      "provider": "vercel",
      "model_id": "o3-pro",
      "input_price_per_million": 20.0,
      "output_price_per_million": 80.0,
      "benchmarks": {
        "aider_polyglot": 0.849
      },
      "model_type": "reasoning"
    },
    {
      "id": "vercel/openai/codex-mini",
      "name": "openai/codex-mini",
      "provider": "vercel",
      "model_id": "codex-mini",
      "input_price_per_million": 1.5,
      "output_price_per_million": 6.0,
      "model_type": "unknown"
    },
    {
      "id": "vercel/mistral/devstral-small",
      "name": "mistral/devstral-small",
      "provider": "vercel",
      "model_id": "devstral-small",
      "input_price_per_million": 0.07,
      "output_price_per_million": 0.28,
      "model_type": "unknown"
    },
    {
      "id": "vercel/google/imagen-4.0-generate-001",
      "name": "google/imagen-4.0-generate-001",
      "provider": "vercel",
      "model_id": "imagen-4.0-generate-001",
      "model_type": "image_gen"
    },
    {
      "id": "vercel/meta/llama-3.2-1b",
      "name": "meta/llama-3.2-1b",
      "provider": "vercel",
      "model_id": "llama-3.2-1b",
      "input_price_per_million": 0.027,
      "output_price_per_million": 0.201,
      "model_type": "chat"
    },
    {
      "id": "vercel/google/imagen-4.0-fast-generate-001",
      "name": "google/imagen-4.0-fast-generate-001",
      "provider": "vercel",
      "model_id": "imagen-4.0-fast-generate-001",
      "model_type": "image_gen"
    },
    {
      "id": "vercel/perplexity/sonar-reasoning",
      "name": "perplexity/sonar-reasoning",
      "provider": "vercel",
      "model_id": "sonar-reasoning",
      "model_type": "unknown"
    },
    {
      "id": "vercel/openai/gpt-3.5-turbo-instruct",
      "name": "openai/gpt-3.5-turbo-instruct",
      "provider": "vercel",
      "model_id": "gpt-3.5-turbo-instruct",
      "input_price_per_million": 0.5,
      "output_price_per_million": 1.5,
      "benchmarks": {
        "gpqa_diamond": 0.272,
        "mmlu": 0.714,
        "math_level_5": 0.159,
        "gsm8k": 0.578,
        "trivia_qa": 0.858,
        "arena_elo": 1202.0
      },
      "model_type": "chat"
    },
    {
      "id": "vercel/google/imagen-4.0-ultra-generate-001",
      "name": "google/imagen-4.0-ultra-generate-001",
      "provider": "vercel",
      "model_id": "imagen-4.0-ultra-generate-001",
      "model_type": "image_gen"
    },
    {
      "id": "vercel/meta/llama-3.2-11b",
      "name": "meta/llama-3.2-11b",
      "provider": "vercel",
      "model_id": "llama-3.2-11b",
      "model_type": "chat"
    },
    {
      "id": "vercel/openai/o3-deep-research",
      "name": "openai/o3-deep-research",
      "provider": "vercel",
      "model_id": "o3-deep-research",
      "input_price_per_million": 10.0,
      "output_price_per_million": 40.0,
      "model_type": "reasoning"
    },
    {
      "id": "vercel/meta/llama-3.2-90b",
      "name": "meta/llama-3.2-90b",
      "provider": "vercel",
      "model_id": "llama-3.2-90b",
      "model_type": "chat"
    },
    {
      "id": "vercel/cohere/command-a",
      "name": "cohere/command-a",
      "provider": "vercel",
      "model_id": "command-a",
      "input_price_per_million": 2.5,
      "output_price_per_million": 10.0,
      "model_type": "unknown"
    },
    {
      "id": "vercel/mistral/codestral-embed",
      "name": "mistral/codestral-embed",
      "provider": "vercel",
      "model_id": "codestral-embed",
      "input_price_per_million": 0.15,
      "model_type": "embedding"
    },
    {
      "id": "vercel/mistral/magistral-small",
      "name": "mistral/magistral-small",
      "provider": "vercel",
      "model_id": "magistral-small",
      "input_price_per_million": 0.5,
      "output_price_per_million": 1.5,
      "benchmarks": {
        "gpqa_diamond": 0.484,
        "otis_mock_aime_2024_2025": 0.3
      },
      "model_type": "unknown"
    },
    {
      "id": "vercel/mistral/mistral-nemo",
      "name": "mistral/mistral-nemo",
      "provider": "vercel",
      "model_id": "mistral-nemo",
      "input_price_per_million": 0.02,
      "output_price_per_million": 0.04,
      "model_type": "chat"
    },
    {
      "id": "vercel/mistral/mixtral-8x22b-instruct",
      "name": "mistral/mixtral-8x22b-instruct",
      "provider": "vercel",
      "model_id": "mixtral-8x22b-instruct",
      "input_price_per_million": 2.0,
      "output_price_per_million": 6.0,
      "model_type": "unknown"
    },
    {
      "id": "vercel/fireworks/models",
      "name": "fireworks/models",
      "provider": "vercel",
      "model_id": "models",
      "model_type": "unknown"
    }
  ]
}