{
  "provider": "anthropic",
  "model_count": 7,
  "models": [
    {
      "id": "anthropic/claude-opus-4-5-20251101",
      "name": "Claude Opus 4.5",
      "provider": "anthropic",
      "model_id": "claude-opus-4-5-20251101",
      "context_window": 200000,
      "input_price_per_million": 5.0,
      "output_price_per_million": 25.0,
      "benchmarks": {
        "gpqa_diamond": 0.807,
        "otis_mock_aime_2024_2025": 0.481,
        "frontiermath": 0.207,
        "simplebench": 0.62,
        "frontiermath_tier_4": 0.042,
        "arena_elo": 1465,
        "swe_bench_verified": 0.809,
        "aider_polyglot": 0.756,
        "terminal_bench": 0.65,
        "osworld": 0.663,
        "arc_agi_2": 0.376,
        "humanitys_last_exam": 0.112
      }
    },
    {
      "id": "anthropic/claude-haiku-4-5-20251001",
      "name": "Claude Haiku 4.5",
      "provider": "anthropic",
      "model_id": "claude-haiku-4-5-20251001",
      "context_window": 200000,
      "input_price_per_million": 1.0,
      "output_price_per_million": 5.0,
      "benchmarks": {
        "gpqa_diamond": 0.605,
        "math_level_5": 0.869,
        "otis_mock_aime_2024_2025": 0.358,
        "frontiermath": 0.041,
        "swe_bench_verified": 0.606,
        "swe_bench": 0.606,
        "livebench_global": 48.34,
        "livebench_reasoning": 33.94,
        "livebench_coding": 72.17,
        "livebench_agentic_coding": 33.33,
        "livebench_math": 57.97,
        "livebench_data_analysis": 66.19,
        "livebench_language": 57.05,
        "livebench_ifeval": 17.75,
        "arena_elo": 1403
      }
    },
    {
      "id": "anthropic/claude-sonnet-4-5-20250929",
      "name": "Claude Sonnet 4.5",
      "provider": "anthropic",
      "model_id": "claude-sonnet-4-5-20250929",
      "context_window": 200000,
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "gpqa_diamond": 0.737,
        "math_level_5": 0.977,
        "otis_mock_aime_2024_2025": 0.356,
        "frontiermath": 0.093,
        "frontiermath_tier_4": 0.021,
        "simpleqa_verified": 0.13,
        "swe_bench_verified": 0.772,
        "deep_research_bench": 0.577,
        "swe_bench": 0.648,
        "livebench_global": 56.6,
        "livebench_reasoning": 42.29,
        "livebench_coding": 76.07,
        "livebench_agentic_coding": 48.33,
        "livebench_math": 62.62,
        "livebench_data_analysis": 67.34,
        "livebench_language": 76.0,
        "livebench_ifeval": 23.52,
        "arena_elo": 1448,
        "aider_polyglot": 0.65,
        "terminal_bench": 0.5,
        "osworld": 0.614
      }
    },
    {
      "id": "anthropic/claude-opus-4-1-20250805",
      "name": "Claude Opus 4.1",
      "provider": "anthropic",
      "model_id": "claude-opus-4-1-20250805",
      "context_window": 200000,
      "input_price_per_million": 15.0,
      "output_price_per_million": 75.0,
      "benchmarks": {
        "gpqa_diamond": 0.732,
        "otis_mock_aime_2024_2025": 0.4,
        "frontiermath": 0.059,
        "simplebench": 0.6,
        "swe_bench_verified": 0.632,
        "deep_research_bench": 0.564,
        "terminal_bench": 0.588,
        "swe_bench": 0.632,
        "livebench_global": 57.54,
        "livebench_reasoning": 40.89,
        "livebench_coding": 76.07,
        "livebench_agentic_coding": 53.33,
        "livebench_math": 62.83,
        "livebench_data_analysis": 66.95,
        "livebench_language": 76.75,
        "livebench_ifeval": 25.92,
        "arena_elo": 1410
      }
    },
    {
      "id": "anthropic/claude-opus-4-20250514",
      "name": "Claude Opus 4",
      "provider": "anthropic",
      "model_id": "claude-opus-4-20250514",
      "context_window": 200000,
      "input_price_per_million": 15.0,
      "output_price_per_million": 75.0,
      "benchmarks": {
        "gpqa_diamond": 0.692,
        "math_level_5": 0.85,
        "otis_mock_aime_2024_2025": 0.422,
        "frontiermath": 0.045,
        "aider_polyglot": 0.618,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.622,
        "deep_research_bench": 0.563,
        "terminal_bench": 0.453,
        "swe_bench": 0.622,
        "arena_elo": 1390
      }
    },
    {
      "id": "anthropic/claude-sonnet-4-20250514",
      "name": "Claude Sonnet 4",
      "provider": "anthropic",
      "model_id": "claude-sonnet-4-20250514",
      "context_window": 200000,
      "input_price_per_million": 3.0,
      "output_price_per_million": 15.0,
      "benchmarks": {
        "gpqa_diamond": 0.667,
        "math_level_5": 0.844,
        "otis_mock_aime_2024_2025": 0.289,
        "frontiermath": 0.041,
        "aider_polyglot": 0.584,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.606,
        "terminal_bench": 0.548,
        "swe_bench": 0.606,
        "livebench_global": 53.93,
        "livebench_reasoning": 39.67,
        "livebench_coding": 80.74,
        "livebench_agentic_coding": 38.33,
        "livebench_math": 60.36,
        "livebench_data_analysis": 64.68,
        "livebench_language": 71.01,
        "livebench_ifeval": 22.68,
        "arena_elo": 1380
      }
    },
    {
      "id": "anthropic/claude-3-haiku-20240307",
      "name": "Claude Haiku 3",
      "provider": "anthropic",
      "model_id": "claude-3-haiku-20240307",
      "context_window": 200000,
      "input_price_per_million": 0.25,
      "output_price_per_million": 1.25,
      "benchmarks": {
        "gpqa_diamond": 0.363,
        "mmlu": 0.738,
        "math_level_5": 0.149,
        "otis_mock_aime_2024_2025": 0.018
      }
    }
  ]
}