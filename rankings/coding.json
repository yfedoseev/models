{
  "generated_at": "2026-01-11T15:02:29.699209",
  "ranking_type": "coding",
  "count": 50,
  "models": [
    {
      "rank": 1,
      "model_id": "anthropic/claude-opus-4-5-20251101",
      "provider": "anthropic",
      "name": "Claude Opus 4.5",
      "score": 0.809,
      "tiebreaker": 0.6897,
      "composite_score": 0.5188,
      "benchmark_count": 12,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.807,
        "otis_mock_aime_2024_2025": 0.481,
        "frontiermath": 0.207,
        "simplebench": 0.62,
        "frontiermath_tier_4": 0.042,
        "arena_elo": 1465,
        "swe_bench_verified": 0.809,
        "aider_polyglot": 0.756,
        "terminal_bench": 0.65,
        "osworld": 0.663,
        "arc_agi_2": 0.376,
        "humanitys_last_exam": 0.112
      }
    },
    {
      "rank": 2,
      "model_id": "anthropic/claude-sonnet-4-5-20250929",
      "provider": "anthropic",
      "name": "Claude Sonnet 4.5",
      "score": 0.772,
      "tiebreaker": 0.5618,
      "composite_score": 0.5211,
      "benchmark_count": 16,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.737,
        "math_level_5": 0.977,
        "otis_mock_aime_2024_2025": 0.356,
        "frontiermath": 0.093,
        "frontiermath_tier_4": 0.021,
        "simpleqa_verified": 0.13,
        "swe_bench_verified": 0.772,
        "deep_research_bench": 0.577,
        "swe_bench": 0.648,
        "livebench_global": 56.6,
        "livebench_reasoning": 42.29,
        "livebench_coding": 76.07,
        "livebench_agentic_coding": 48.33,
        "livebench_math": 62.62,
        "livebench_data_analysis": 67.34,
        "livebench_language": 76.0,
        "livebench_ifeval": 23.52,
        "arena_elo": 1448,
        "aider_polyglot": 0.65,
        "terminal_bench": 0.5,
        "osworld": 0.614
      }
    },
    {
      "rank": 3,
      "model_id": "openai/gpt-5.1-codex",
      "provider": "openai",
      "name": "gpt-5.1-codex",
      "score": 0.763,
      "tiebreaker": 0.5333,
      "composite_score": 0.7244,
      "benchmark_count": 6,
      "intelligence_tier": "P",
      "benchmarks": {
        "livebench_global": 69.76,
        "livebench_reasoning": 81.98,
        "livebench_coding": 71.78,
        "livebench_agentic_coding": 53.33,
        "livebench_math": 79.58,
        "livebench_data_analysis": 68.8,
        "livebench_language": 69.48,
        "livebench_ifeval": 63.39,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 4,
      "model_id": "openai/gpt-5-pro-2025-10-06",
      "provider": "openai",
      "name": "gpt-5-pro-2025-10-06",
      "score": 0.763,
      "tiebreaker": 0.5167,
      "composite_score": 0.7088,
      "benchmark_count": 7,
      "intelligence_tier": "P",
      "benchmarks": {
        "simplebench": 0.616,
        "livebench_global": 72.67,
        "livebench_reasoning": 81.69,
        "livebench_coding": 72.11,
        "livebench_agentic_coding": 51.67,
        "livebench_math": 86.17,
        "livebench_data_analysis": 72.42,
        "livebench_language": 80.69,
        "livebench_ifeval": 63.96,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 5,
      "model_id": "openai/gpt-5.1-codex-mini",
      "provider": "openai",
      "name": "gpt-5.1-codex-mini",
      "score": 0.763,
      "tiebreaker": 0.4,
      "composite_score": 0.6824,
      "benchmark_count": 6,
      "intelligence_tier": "P",
      "benchmarks": {
        "livebench_global": 63.32,
        "livebench_reasoning": 64.71,
        "livebench_coding": 69.93,
        "livebench_agentic_coding": 40.0,
        "livebench_math": 76.26,
        "livebench_data_analysis": 70.29,
        "livebench_language": 63.01,
        "livebench_ifeval": 59.02,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 6,
      "model_id": "openai/gpt-5-nano-2025-08-07",
      "provider": "openai",
      "name": "gpt-5-nano-2025-08-07",
      "score": 0.763,
      "tiebreaker": 0.2833,
      "composite_score": 0.6323,
      "benchmark_count": 6,
      "intelligence_tier": "P",
      "benchmarks": {
        "livebench_global": 51.61,
        "livebench_reasoning": 35.45,
        "livebench_coding": 67.38,
        "livebench_agentic_coding": 28.33,
        "livebench_math": 64.7,
        "livebench_data_analysis": 65.73,
        "livebench_language": 47.73,
        "livebench_ifeval": 51.98,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 7,
      "model_id": "openai/gpt-5-2025-08-07",
      "provider": "openai",
      "name": "gpt-5-2025-08-07",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.795,
      "benchmark_count": 4,
      "intelligence_tier": "P",
      "benchmarks": {
        "arena_elo": 1425.0,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 8,
      "model_id": "openai/gpt-5-mini-2025-08-07",
      "provider": "openai",
      "name": "gpt-5-mini-2025-08-07",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.8197,
      "benchmark_count": 3,
      "intelligence_tier": "P",
      "benchmarks": {
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 9,
      "model_id": "openai/gpt-5-codex",
      "provider": "openai",
      "name": "gpt-5-codex",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.8197,
      "benchmark_count": 3,
      "intelligence_tier": "P",
      "benchmarks": {
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 10,
      "model_id": "openai/gpt-5-search-api",
      "provider": "openai",
      "name": "gpt-5-search-api",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.8197,
      "benchmark_count": 3,
      "intelligence_tier": "P",
      "benchmarks": {
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 11,
      "model_id": "openai/gpt-5.1-chat-latest",
      "provider": "openai",
      "name": "gpt-5.1-chat-latest",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.7987,
      "benchmark_count": 4,
      "intelligence_tier": "P",
      "benchmarks": {
        "arena_elo": 1435.0,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 12,
      "model_id": "openai/gpt-5.1-codex-max",
      "provider": "openai",
      "name": "gpt-5.1-codex-max",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.8197,
      "benchmark_count": 3,
      "intelligence_tier": "P",
      "benchmarks": {
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 13,
      "model_id": "openai/gpt-5.2-2025-12-11",
      "provider": "openai",
      "name": "gpt-5.2-2025-12-11",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.795,
      "benchmark_count": 4,
      "intelligence_tier": "P",
      "benchmarks": {
        "arena_elo": 1425.0,
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 14,
      "model_id": "openai/gpt-5.2-pro-2025-12-11",
      "provider": "openai",
      "name": "gpt-5.2-pro-2025-12-11",
      "score": 0.763,
      "tiebreaker": 0.0,
      "composite_score": 0.8197,
      "benchmark_count": 3,
      "intelligence_tier": "P",
      "benchmarks": {
        "swe_bench_verified": 0.763,
        "gpqa_diamond": 0.842,
        "mmlu": 0.923
      }
    },
    {
      "rank": 15,
      "model_id": "openai/o3-mini-2025-01-31",
      "provider": "openai",
      "name": "o3-mini-2025-01-31",
      "score": 0.691,
      "tiebreaker": 0.0,
      "composite_score": 0.7204,
      "benchmark_count": 9,
      "intelligence_tier": "P",
      "benchmarks": {
        "mmlu": 85.9,
        "humaneval": 96.3,
        "arena_elo": 1433,
        "swe_bench_verified": 0.691,
        "gpqa_diamond": 0.877,
        "aime_2024": 0.916,
        "aime_2025": 0.889,
        "arc_agi_2": 0.326,
        "scale_multichallenge": 0.5651
      }
    },
    {
      "rank": 16,
      "model_id": "openai/o3-2025-04-16",
      "provider": "openai",
      "name": "o3-2025-04-16",
      "score": 0.691,
      "tiebreaker": 0.0,
      "composite_score": 0.7194,
      "benchmark_count": 9,
      "intelligence_tier": "P",
      "benchmarks": {
        "mmlu": 92.9,
        "humaneval": 87.4,
        "arena_elo": 1433,
        "swe_bench_verified": 0.691,
        "gpqa_diamond": 0.877,
        "aime_2024": 0.916,
        "aime_2025": 0.889,
        "arc_agi_2": 0.326,
        "scale_multichallenge": 0.5651
      }
    },
    {
      "rank": 17,
      "model_id": "openai/o4-mini-2025-04-16",
      "provider": "openai",
      "name": "o4-mini-2025-04-16",
      "score": 0.681,
      "tiebreaker": 0.0,
      "composite_score": 0.7646,
      "benchmark_count": 8,
      "intelligence_tier": "P",
      "benchmarks": {
        "mmlu": 0.9,
        "humaneval": 0.973,
        "arena_elo": 1391,
        "swe_bench_verified": 0.681,
        "gpqa_diamond": 0.811,
        "aime_2024": 0.934,
        "aime_2025": 0.927,
        "scale_multichallenge": 0.4299
      }
    },
    {
      "rank": 18,
      "model_id": "anthropic/claude-opus-4-1-20250805",
      "provider": "anthropic",
      "name": "Claude Opus 4.1",
      "score": 0.632,
      "tiebreaker": 0.5606,
      "composite_score": 0.5563,
      "benchmark_count": 12,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.732,
        "otis_mock_aime_2024_2025": 0.4,
        "frontiermath": 0.059,
        "simplebench": 0.6,
        "swe_bench_verified": 0.632,
        "deep_research_bench": 0.564,
        "terminal_bench": 0.588,
        "swe_bench": 0.632,
        "livebench_global": 57.54,
        "livebench_reasoning": 40.89,
        "livebench_coding": 76.07,
        "livebench_agentic_coding": 53.33,
        "livebench_math": 62.83,
        "livebench_data_analysis": 66.95,
        "livebench_language": 76.75,
        "livebench_ifeval": 25.92,
        "arena_elo": 1410
      }
    },
    {
      "rank": 19,
      "model_id": "google/gemini-2.5-pro",
      "provider": "google",
      "name": "gemini-2.5-pro",
      "score": 0.631,
      "tiebreaker": 0.769,
      "composite_score": 0.5515,
      "benchmark_count": 8,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.853,
        "otis_mock_aime_2024_2025": 0.842,
        "frontiermath": 0.141,
        "frontiermath_tier_4": 0.042,
        "simpleqa_verified": 0.56,
        "chess_puzzles": 0.2,
        "arena_elo": 1438,
        "swe_bench_verified": 0.631,
        "aider_polyglot": 0.769
      }
    },
    {
      "rank": 20,
      "model_id": "google/gemini-2.5-pro-preview-tts",
      "provider": "google",
      "name": "gemini-2.5-pro-preview-tts",
      "score": 0.631,
      "tiebreaker": 0.769,
      "composite_score": 0.7472,
      "benchmark_count": 4,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.853,
        "swe_bench_verified": 0.631,
        "aider_polyglot": 0.769,
        "arena_elo": 1438
      }
    },
    {
      "rank": 21,
      "model_id": "bedrock/anthropic.claude-opus-4-20250514-v1:0",
      "provider": "bedrock",
      "name": "Claude Opus 4",
      "score": 0.622,
      "tiebreaker": 0.58,
      "composite_score": 0.4827,
      "benchmark_count": 10,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.692,
        "math_level_5": 0.85,
        "otis_mock_aime_2024_2025": 0.422,
        "frontiermath": 0.045,
        "aider_polyglot": 70.7,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.622,
        "deep_research_bench": 0.563,
        "terminal_bench": 0.453,
        "swe_bench": 0.622
      }
    },
    {
      "rank": 22,
      "model_id": "anthropic/claude-sonnet-4-20250514",
      "provider": "anthropic",
      "name": "Claude Sonnet 4",
      "score": 0.606,
      "tiebreaker": 0.5051,
      "composite_score": 0.4843,
      "benchmark_count": 13,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.667,
        "math_level_5": 0.844,
        "otis_mock_aime_2024_2025": 0.289,
        "frontiermath": 0.041,
        "aider_polyglot": 0.584,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.606,
        "terminal_bench": 0.548,
        "swe_bench": 0.606,
        "livebench_global": 53.93,
        "livebench_reasoning": 39.67,
        "livebench_coding": 80.74,
        "livebench_agentic_coding": 38.33,
        "livebench_math": 60.36,
        "livebench_data_analysis": 64.68,
        "livebench_language": 71.01,
        "livebench_ifeval": 22.68,
        "arena_elo": 1380
      }
    },
    {
      "rank": 23,
      "model_id": "anthropic/claude-haiku-4-5-20251001",
      "provider": "anthropic",
      "name": "Claude Haiku 4.5",
      "score": 0.606,
      "tiebreaker": 0.3333,
      "composite_score": 0.5064,
      "benchmark_count": 10,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.605,
        "math_level_5": 0.869,
        "otis_mock_aime_2024_2025": 0.358,
        "frontiermath": 0.041,
        "swe_bench_verified": 0.606,
        "swe_bench": 0.606,
        "livebench_global": 48.34,
        "livebench_reasoning": 33.94,
        "livebench_coding": 72.17,
        "livebench_agentic_coding": 33.33,
        "livebench_math": 57.97,
        "livebench_data_analysis": 66.19,
        "livebench_language": 57.05,
        "livebench_ifeval": 17.75,
        "arena_elo": 1403
      }
    },
    {
      "rank": 24,
      "model_id": "bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0",
      "provider": "bedrock",
      "name": "Claude 3.7 Sonnet",
      "score": 0.522,
      "tiebreaker": 0.604,
      "composite_score": 0.4526,
      "benchmark_count": 7,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.66,
        "math_level_5": 0.682,
        "otis_mock_aime_2024_2025": 0.219,
        "frontiermath": 0.031,
        "aider_polyglot": 60.4,
        "simplebench": 0.449,
        "swe_bench_verified": 0.522
      }
    },
    {
      "rank": 25,
      "model_id": "bedrock/deepseek.v3-v1:0",
      "provider": "bedrock",
      "name": "DeepSeek-V3.1",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 26,
      "model_id": "fireworks/deepseek-v3-0324",
      "provider": "fireworks",
      "name": "Deepseek V3 03-24",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "F",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 27,
      "model_id": "ollama/deepseek-v2",
      "provider": "ollama",
      "name": "deepseek-v2",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 28,
      "model_id": "ollama/deepseek-v3.1",
      "provider": "ollama",
      "name": "deepseek-v3.1",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 29,
      "model_id": "ollama/deepseek-v2.5",
      "provider": "ollama",
      "name": "deepseek-v2.5",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 30,
      "model_id": "xinference/deepseek",
      "provider": "xinference",
      "name": "deepseek",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 31,
      "model_id": "xinference/DeepSeek-V3.2",
      "provider": "xinference",
      "name": "DeepSeek-V3.2",
      "score": 0.521,
      "tiebreaker": 0.178,
      "composite_score": 0.3802,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.565,
        "mmlu": 0.871,
        "math_level_5": 0.649,
        "otis_mock_aime_2024_2025": 0.158,
        "frontiermath": 0.017,
        "aider_polyglot": 17.8,
        "simplebench": 0.189,
        "trivia_qa": 0.829,
        "swe_bench_verified": 0.521,
        "arena_elo": 1306.0
      }
    },
    {
      "rank": 32,
      "model_id": "openai/gpt-4.1-2025-04-14",
      "provider": "openai",
      "name": "gpt-4.1-2025-04-14",
      "score": 0.41,
      "tiebreaker": 0.524,
      "composite_score": 0.4396,
      "benchmark_count": 11,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.669,
        "mmlu": 90.2,
        "math_level_5": 0.83,
        "otis_mock_aime_2024_2025": 0.383,
        "frontiermath": 0.055,
        "aider_polyglot": 52.4,
        "simplebench": 0.27,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.41,
        "humaneval": 94.5,
        "arena_elo": 1412.0
      }
    },
    {
      "rank": 33,
      "model_id": "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0:18k",
      "provider": "bedrock",
      "name": "Claude 3.5 Sonnet v2",
      "score": 0.406,
      "tiebreaker": 0.516,
      "composite_score": 0.3196,
      "benchmark_count": 9,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.54,
        "mmlu": 0.873,
        "math_level_5": 0.517,
        "otis_mock_aime_2024_2025": 0.085,
        "frontiermath": 0.021,
        "aider_polyglot": 51.6,
        "simplebench": 0.275,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.406
      }
    },
    {
      "rank": 34,
      "model_id": "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0:51k",
      "provider": "bedrock",
      "name": "Claude 3.5 Sonnet v2",
      "score": 0.406,
      "tiebreaker": 0.516,
      "composite_score": 0.3196,
      "benchmark_count": 9,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.54,
        "mmlu": 0.873,
        "math_level_5": 0.517,
        "otis_mock_aime_2024_2025": 0.085,
        "frontiermath": 0.021,
        "aider_polyglot": 51.6,
        "simplebench": 0.275,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.406
      }
    },
    {
      "rank": 35,
      "model_id": "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0:200k",
      "provider": "bedrock",
      "name": "Claude 3.5 Sonnet v2",
      "score": 0.406,
      "tiebreaker": 0.516,
      "composite_score": 0.3196,
      "benchmark_count": 9,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.54,
        "mmlu": 0.873,
        "math_level_5": 0.517,
        "otis_mock_aime_2024_2025": 0.085,
        "frontiermath": 0.021,
        "aider_polyglot": 51.6,
        "simplebench": 0.275,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.406
      }
    },
    {
      "rank": 36,
      "model_id": "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0",
      "provider": "bedrock",
      "name": "Claude 3.5 Sonnet v2",
      "score": 0.406,
      "tiebreaker": 0.516,
      "composite_score": 0.3196,
      "benchmark_count": 9,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.54,
        "mmlu": 0.873,
        "math_level_5": 0.517,
        "otis_mock_aime_2024_2025": 0.085,
        "frontiermath": 0.021,
        "aider_polyglot": 51.6,
        "simplebench": 0.275,
        "frontiermath_tier_4": 0.0,
        "swe_bench_verified": 0.406
      }
    },
    {
      "rank": 37,
      "model_id": "bedrock/deepseek.r1-v1:0",
      "provider": "bedrock",
      "name": "DeepSeek-R1",
      "score": 0.333,
      "tiebreaker": 0.569,
      "composite_score": 0.5133,
      "benchmark_count": 8,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.692,
        "math_level_5": 0.931,
        "otis_mock_aime_2024_2025": 0.533,
        "aider_polyglot": 56.9,
        "simplebench": 0.309,
        "simpleqa_verified": 0.274,
        "swe_bench_verified": 0.333,
        "arena_elo": 1396.0
      }
    },
    {
      "rank": 38,
      "model_id": "fireworks/deepseek-r1",
      "provider": "fireworks",
      "name": "DeepSeek R1 (Fast)",
      "score": 0.333,
      "tiebreaker": 0.569,
      "composite_score": 0.5133,
      "benchmark_count": 8,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.692,
        "math_level_5": 0.931,
        "otis_mock_aime_2024_2025": 0.533,
        "aider_polyglot": 56.9,
        "simplebench": 0.309,
        "simpleqa_verified": 0.274,
        "swe_bench_verified": 0.333,
        "arena_elo": 1396.0
      }
    },
    {
      "rank": 39,
      "model_id": "openai/gpt-4.1-mini-2025-04-14",
      "provider": "openai",
      "name": "gpt-4.1-mini-2025-04-14",
      "score": 0.328,
      "tiebreaker": 0.324,
      "composite_score": 0.4894,
      "benchmark_count": 9,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.658,
        "mmlu": 87.5,
        "math_level_5": 0.873,
        "otis_mock_aime_2024_2025": 0.447,
        "frontiermath": 0.045,
        "aider_polyglot": 32.4,
        "swe_bench_verified": 0.328,
        "humaneval": 93.8,
        "arena_elo": 1381.0
      }
    },
    {
      "rank": 40,
      "model_id": "qwen/qwen-plus",
      "provider": "qwen",
      "name": "qwen/qwen-plus",
      "score": 0.28,
      "tiebreaker": 0.0,
      "composite_score": 0.3431,
      "benchmark_count": 6,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.481,
        "math_level_5": 0.653,
        "otis_mock_aime_2024_2025": 0.178,
        "frontiermath": 0.017,
        "swe_bench_verified": 0.28,
        "arena_elo": 1345.0
      }
    },
    {
      "rank": 41,
      "model_id": "qwen/qwen-plus-latest",
      "provider": "qwen",
      "name": "qwen/qwen-plus-latest",
      "score": 0.28,
      "tiebreaker": 0.0,
      "composite_score": 0.3431,
      "benchmark_count": 6,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.481,
        "math_level_5": 0.653,
        "otis_mock_aime_2024_2025": 0.178,
        "frontiermath": 0.017,
        "swe_bench_verified": 0.28,
        "arena_elo": 1345.0
      }
    },
    {
      "rank": 42,
      "model_id": "openai/gpt-4o",
      "provider": "openai",
      "name": "gpt-4o",
      "score": 0.254,
      "tiebreaker": 0.182,
      "composite_score": 0.3235,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.489,
        "mmlu": 87.2,
        "math_level_5": 0.533,
        "otis_mock_aime_2024_2025": 0.062,
        "frontiermath": 0.003,
        "aider_polyglot": 18.2,
        "simplebench": 0.178,
        "swe_bench_verified": 0.254,
        "humaneval": 91.0,
        "arena_elo": 1345
      }
    },
    {
      "rank": 43,
      "model_id": "openai/chatgpt-4o-latest",
      "provider": "openai",
      "name": "chatgpt-4o-latest",
      "score": 0.254,
      "tiebreaker": 0.182,
      "composite_score": 0.322,
      "benchmark_count": 10,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.489,
        "mmlu": 87.2,
        "math_level_5": 0.533,
        "otis_mock_aime_2024_2025": 0.062,
        "frontiermath": 0.003,
        "aider_polyglot": 18.2,
        "simplebench": 0.178,
        "swe_bench_verified": 0.254,
        "humaneval": 91.0,
        "arena_elo": 1335.0
      }
    },
    {
      "rank": 44,
      "model_id": "vertex/publishers/google/models/gemini-2.0-flash-001",
      "provider": "vertex",
      "name": "publishers/google/models/gemini-2.0-flash-001",
      "score": 0.22,
      "tiebreaker": 0.0,
      "composite_score": 0.4067,
      "benchmark_count": 6,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.641,
        "math_level_5": 0.822,
        "otis_mock_aime_2024_2025": 0.311,
        "frontiermath": 0.017,
        "swe_bench_verified": 0.22,
        "arena_elo": 1360.0
      }
    },
    {
      "rank": 45,
      "model_id": "openai/o1-2024-12-17",
      "provider": "openai",
      "name": "o1-2024-12-17",
      "score": 0.924,
      "tiebreaker": 0.0,
      "composite_score": 0.6677,
      "benchmark_count": 8,
      "intelligence_tier": "P",
      "benchmarks": {
        "gpqa_diamond": 0.781,
        "mmlu": 0.908,
        "math_level_5": 0.816,
        "otis_mock_aime_2024_2025": 0.311,
        "simplebench": 0.417,
        "humaneval": 0.924,
        "arena_elo": 1401,
        "aime_2024": 0.833
      }
    },
    {
      "rank": 46,
      "model_id": "openai/o1-pro-2025-03-19",
      "provider": "openai",
      "name": "o1-pro-2025-03-19",
      "score": 0.924,
      "tiebreaker": 0.0,
      "composite_score": 0.7975,
      "benchmark_count": 5,
      "intelligence_tier": "P",
      "benchmarks": {
        "arena_elo": 1401,
        "gpqa_diamond": 0.781,
        "aime_2024": 0.833,
        "humaneval": 0.924,
        "mmlu": 0.908
      }
    },
    {
      "rank": 47,
      "model_id": "azure/eu/o1-mini",
      "provider": "azure_openai",
      "name": "eu/o1-mini",
      "score": 0.924,
      "tiebreaker": 0.0,
      "composite_score": 0.724,
      "benchmark_count": 3,
      "intelligence_tier": "P",
      "benchmarks": {
        "mmlu": 85.2,
        "humaneval": 92.4,
        "arena_elo": 1336.0
      }
    },
    {
      "rank": 48,
      "model_id": "openai/gpt-4-turbo-preview",
      "provider": "openai",
      "name": "gpt-4-turbo-preview",
      "score": 0.882,
      "tiebreaker": 0.0,
      "composite_score": 0.432,
      "benchmark_count": 7,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.466,
        "mmlu": 86.7,
        "math_level_5": 0.467,
        "otis_mock_aime_2024_2025": 0.067,
        "simplebench": 0.251,
        "humaneval": 88.2,
        "arena_elo": 1324
      }
    },
    {
      "rank": 49,
      "model_id": "grok-4-0709",
      "provider": "xai",
      "name": "grok-4-0709",
      "score": 0.796,
      "tiebreaker": 0.548,
      "composite_score": 0.5399,
      "benchmark_count": 11,
      "intelligence_tier": "S",
      "benchmarks": {
        "gpqa_diamond": 0.87,
        "otis_mock_aime_2024_2025": 0.84,
        "frontiermath": 0.197,
        "aider_polyglot": 79.6,
        "simplebench": 0.605,
        "frontiermath_tier_4": 0.021,
        "simpleqa_verified": 0.479,
        "chess_puzzles": 0.351,
        "arena_elo": 1409.0,
        "livebench_global": 62.9,
        "livebench_reasoning": 79.13,
        "livebench_coding": 73.13,
        "livebench_agentic_coding": 30.0,
        "livebench_math": 83.02,
        "livebench_data_analysis": 69.53,
        "livebench_language": 76.39,
        "livebench_ifeval": 29.07
      }
    },
    {
      "rank": 50,
      "model_id": "fireworks/qwen3-235b-a22b",
      "provider": "fireworks",
      "name": "Qwen3 235B A22B",
      "score": 0.596,
      "tiebreaker": 0.596,
      "composite_score": 0.5741,
      "benchmark_count": 5,
      "intelligence_tier": "F",
      "benchmarks": {
        "gpqa_diamond": 0.707,
        "math_level_5": 0.689,
        "aider_polyglot": 59.6,
        "simplebench": 0.31,
        "arena_elo": 1374.0
      }
    }
  ]
}